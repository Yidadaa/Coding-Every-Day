## 周报汇报
> 2017.8.28 - 9.1   

### 机器学习基础课程学习
> 所用教材：《统计学习方法》- 李航.清华大学出版社。  
> 进度：阅读1-7章，共计11章。

- 第一章**统计学习方法概论**，概述了机器学习中的各种基础概念，包括：监督学习、半监督学习和非监督学习；统计学习中的要素；机器学习模型的评估与选择；正则化及交叉验证技巧及方法；模型的泛化误差；标注问题及回归问题。
- 第二章**感知机模型**，学习了感知机这一最基本的二分类模型，并用代码实现了一个感知机，代码地址：[Yidadaa/CodingEveryDay](https://github.com/Yidadaa/CodingEveryDay/blob/master/2017/machineLearning/preceptron/preceptron.py)。
- 第三章**k近邻法**，学习了k近邻模型，并代码实现了k近邻树的构造与搜索剪枝算法，代码地址：[Yidadaa/CodingEveryDay](https://github.com/Yidadaa/CodingEveryDay/blob/master/2017/machineLearning/kNN/k-nearest_neighbor.py)。
- 第四章**朴素贝叶斯法**，学习朴素贝叶斯的基本概念，同时发现自己概率论基础不好，数学推导看起来很吃力，利用代码解决了一道课后习题：[Yidadaa/CodingEveryDay](https://github.com/Yidadaa/CodingEveryDay/blob/master/2017/machineLearning/naiveBayes/naive_bayes.py)。
- 第五章**决策树模型**，本章内容信息量较大，介绍了决策树模型的基本概念，并且引入了特征选择时的信息增益及经验熵等概念，代码实现了一种决策树的生成算法及剪枝算法（ID3），代码地址：[Yidadaa/CodingEveryDay](https://github.com/Yidadaa/CodingEveryDay/blob/master/2017/machineLearning/decisionTree/ID3_C4.5.py)。
- 第六章**逻辑斯底回归与最大熵模型**，此章内容十分偏向理论，对数学基础要求较高，看的云里雾里，最终没有弄明白这章的内容，只知道logistic回归是一种非线性分类模型，而最大熵则是概率模型学习的一个准则。书中没有举例说明如何利用这两个概念来解决实际问题，所以没有代码实现。
- 第七章**支持向量机**，SVM可以说是十分常见的分类器了，此章讲解了线性可分支持向量机、线性支持向量机和非线性支持向量机，以及软间隔最大化和硬间隔最大化，这章内容较多，目前还没有看完。

**总结**：李航老师的这本书比较偏向理论，我觉得需要配合一本有实例讲解的书籍配套使用，暂时确定为《机器学习实战》。

### 进阶课程学习
在了解了基础的机器学习概念后，我开始搭配CS231n进行学习，该课程包含了三个assignment，每个assignment都循序渐进地设定了各种各样的编码任务，逐渐地学习kNN、SVM、Softmax以及FCN和RNN等概念的具体实现，搭配社区里的中文翻译，学习起来十分方便。

进度：assignment1 - `1 complete / 4 all`。
